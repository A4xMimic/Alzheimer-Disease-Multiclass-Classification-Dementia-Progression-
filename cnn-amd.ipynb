{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8797169,"sourceType":"datasetVersion","datasetId":5289787}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os \nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport keras \nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\nfrom imblearn.over_sampling import SMOTE","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images = []\nlabels = []\nfor subfolder in tqdm(os.listdir('/kaggle/input/alzheimers-multiclass-dataset-equal-and-augmented')):\n    subfolder_path = os.path.join('/kaggle/input/alzheimers-multiclass-dataset-equal-and-augmented', subfolder)\n    for folder in os.listdir(subfolder_path):\n        subfolder_path2=os.path.join(subfolder_path,folder)\n        for image_filename in os.listdir(subfolder_path2):\n            image_path = os.path.join(subfolder_path2, image_filename)\n            images.append(image_path)\n            labels.append(folder)\ndf = pd.DataFrame({'image': images, 'label': labels})\ndf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming `df` is your DataFrame and `label` is the column with class labels\nclass_counts = df['label'].value_counts()\n\n# Print exact counts\nprint(\"Exact counts for each class:\")\nprint(class_counts)\n\n# Plot the class distribution\nplt.figure(figsize=(15, 8))\nax = sns.countplot(x=df['label'], palette='Set1')\nax.set_xlabel(\"Class\", fontsize=20)\nax.set_ylabel(\"Count\", fontsize=20)\nplt.title('The Number Of Samples For Each Class', fontsize=20)\nplt.grid(True)\nplt.xticks(rotation=45)\n\n# Annotate each bar with the exact count\nfor p in ax.patches:\n    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5), \n                textcoords='offset points')\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport random\n\nsample_df = df.sample(36).reset_index(drop=True)\n\nplt.figure(figsize=(15, 15))\n\nfor i in range(36):\n    plt.subplot(6, 6, i + 1)\n    img = mpimg.imread(sample_df['image'][i])  \n    plt.imshow(img)\n    plt.title(sample_df['label'][i]) \n    plt.axis('off')  \nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test1, y_train, y_test1 = train_test_split(df['image'], df['label'], test_size=0.2, random_state=42,shuffle=True,stratify=df['label'])\nX_val, X_test, y_val, y_test = train_test_split(X_test1,y_test1, test_size=0.5, random_state=42,shuffle=True,stratify=y_test1)\ndf_train = pd.DataFrame({'image': X_train, 'label': y_train})\ndf_test = pd.DataFrame({'image': X_test, 'label': y_test})\ndf_val = pd.DataFrame({'image': X_val, 'label': y_val})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_size = (224,224)\nbatch_size = 32\ndatagen = ImageDataGenerator(\n    preprocessing_function= tf.keras.applications.vgg16.preprocess_input,\n    rescale=1./255,\n    horizontal_flip=True\n)\ntrain_generator = datagen.flow_from_dataframe(\n    df_train,\n    x_col='image',\n    y_col='label',\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    color_mode='rgb',\n    shuffle=True\n)\ntest_generator = datagen.flow_from_dataframe(\n    df_test,\n    x_col='image',\n    y_col='label',\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    color_mode='rgb',\n    shuffle=False\n)\nval_generator = datagen.flow_from_dataframe(\n    df_val,\n    x_col='image',\n    y_col='label',\n    color_mode='rgb',\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_num=list(train_generator.class_indices.keys())\nclass_num","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n    layers.BatchNormalization(),\n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    layers.Dropout(0.25),\n\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    layers.Dropout(0.25),\n\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    layers.Dropout(0.25),\n\n    layers.Conv2D(256, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.Conv2D(256, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    layers.Dropout(0.5),\n\n    layers.Flatten(),\n    layers.Dense(256, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    layers.Dense(128, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    \n    layers.Dense(4, activation='softmax')\n])\n\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stopping_cb =EarlyStopping(patience=10, restore_best_weights=True)\nmodel.compile(optimizer ='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_generator, epochs=50, validation_data=val_generator, callbacks=[early_stopping_cb])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('/kaggle/working/model_Cnn2.keras')\nmodel.export('/kaggle/working/model_Cnn2')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss,accuracy=model.evaluate(test_generator)\nprint(\"loss : \",loss)\nprint(\"accuracy : \",accuracy)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ef=pd.DataFrame(history.history)\nef[['loss','val_loss']].plot()\nef[['accuracy','val_accuracy']].plot()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_test =test_generator.classes\npredictions = model.predict(test_generator)\ny_pred = np.argmax(predictions,axis=1)\ny_test = np.ravel(y_test)\ny_pred = np.ravel(y_pred)\ndf = pd.DataFrame({'Actual': y_test, 'Prediction': y_pred})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"correct_predictions = (y_test == y_pred).sum()\nincorrect_predictions = (y_test != y_pred).sum()\n\nlabels = ['Correct', 'Incorrect']\nsizes = [correct_predictions, incorrect_predictions]\n\nplt.figure(figsize=(8, 6))\nplt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\nplt.title('Percentage of Correct vs Incorrect Prediction')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(30,70))\nbatch = next(test_generator)\nimages= batch[0]\nfor n in range(32):\n    plt.subplot(8,4,n+1)\n    plt.imshow(images[n])\n    plt.axis('off')\n    plt.title(f\"Actual: {class_num[y_test[n]]}, \\n Predicted: {class_num[y_pred[n]]}.\\n Confidence: {round(predictions[n][np.argmax(predictions[n])],0)}%\",fontsize=20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel = load_model('/kaggle/working/model_Cnn2.keras')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef predict_single_image(model, image_path, class_num, target_size=(224, 224)):\n    \"\"\"\n    Predicts the class of a single image and displays it with the prediction and confidence.\n    \n    Args:\n        model: Trained Keras model.\n        image_path (str): Path to the image file.\n        class_num (dict): Dictionary mapping class indices to class labels.\n        target_size (tuple): Target size for resizing the image.\n    \"\"\"\n    # Load and preprocess the image\n    image = load_img(image_path, target_size=target_size)\n    image_array = img_to_array(image)  # Convert to numpy array\n    image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n    image_array = image_array / 255.0  # Normalize\n    \n    # Predict\n    predictions = model.predict(image_array)\n    predicted_class_index = np.argmax(predictions)\n    predicted_class_label = class_num[predicted_class_index]\n    confidence = round(np.max(predictions) * 100, 2)\n    \n    # Display the image and prediction\n    plt.imshow(image)\n    plt.axis('off')\n    plt.title(f\"Predicted: {predicted_class_label}\\nConfidence: {confidence}%\", fontsize=16)\n    plt.show()\n\n# Example Usage\nimage_path = \"/kaggle/input/alzheimers-multiclass-dataset-equal-and-augmented/combined_images/VeryMildDemented/0073c8fe-469d-4160-9344-37d61ac6f9bd.jpg\"\nclass_num = {0: 'MildDemented', 1: 'ModerateDemented', 2: 'NonDemented', 3: 'VeryMildDemented'}\npredict_single_image(model, image_path, class_num)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}